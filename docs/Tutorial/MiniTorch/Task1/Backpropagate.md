这一节请参考 [Backpropagate](https://minitorch.github.io/module1/backpropagate/)

反向传播可以计算一次运算的导数，再加上链式法则，就可以计算两个连续运算的导数，以至于任意一系列运算的导数。

可以发现我们的计算图是一个有向无环图，这意味着我们可以使用拓扑排序来依次计算每个节点

反向传播应该运行以下算法：

1. 调用拓扑排序以获取一个有序队列
2. 创建一个标量和当前导数的字典
3. 对于倒序的每个节点，从队列中取出一个完成的标量和导数：
    a. 如果标量是叶节点，添加其最终导数（累积导数）并循环到（1）
    b. 如果标量不是叶节点，1）在最后一个函数上调用 .chain_rule，带入 `dout` 2）遍历链式法则产生的所有标量+导数 3）在字典中为标量累积导数

最后注意：只有叶标量应该有非 None 的 `.derivative` 值。所有中间标量应该只在字典中保持他们当前的导数值。这有点烦人，但它遵循了 PyTorch 的行为。